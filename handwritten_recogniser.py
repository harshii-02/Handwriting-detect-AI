# -*- coding: utf-8 -*-
"""handwritten recogniser.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1D4NXZFyA9aP396g_qg9rLdVm5EicW5Oq
"""

!pip install tensorflow matplotlib numpy

import tensorflow as tf
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
import matplotlib.pyplot as plt

# Load dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normalize the pixel values
x_train, x_test = x_train / 255.0, x_test / 255.0

# Visualize a sample
plt.imshow(x_train[0], cmap='gray')
plt.title(f"Label: {y_train[0]}")
plt.show()

# Build the model
model = Sequential([
    Flatten(input_shape=(28, 28)),
    Dense(128, activation='relu'),
    Dense(10, activation='softmax')  # 10 digits (0-9)
])

# Compile the model
model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

# Train the model
model.fit(x_train, y_train, epochs=5)

# Evaluate the model
test_loss, test_acc = model.evaluate(x_test, y_test)
print(f"Test Accuracy: {test_acc:.2f}")

!pip install easyocr

!pip install matplotlib Pillow

from google.colab import files
uploaded = files.upload()


import easyocr
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import numpy as np


image_path = list(uploaded.keys())[0]


image = cv2.imread(image_path)
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

reader = easyocr.Reader(['en'])


results = reader.readtext(image)


for (bbox, text, confidence) in results:
    print(f"Detected: '{text}' with {confidence:.2f} confidence")

    (top_left, top_right, bottom_right, bottom_left) = bbox
    top_left = tuple([int(val) for val in top_left])
    bottom_right = tuple([int(val) for val in bottom_right])

    cv2.rectangle(image_rgb, top_left, bottom_right, (0, 255, 0), 2)
    cv2.putText(image_rgb, text, top_left, cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)

plt.figure(figsize=(10, 10))
plt.imshow(image_rgb)
plt.axis('off')
plt.title("Detected Text and Digits")
plt.show()

from google.colab import files
uploaded = files.upload()


from PIL import Image
image_path = list(uploaded.keys())[0]
image = Image.open(image_path).convert("RGB")



if image.width > 1024:
    ratio = 1024 / image.width
    new_size = (1024, int(image.height * ratio))
    image = image.resize(new_size)


from transformers import TrOCRProcessor, VisionEncoderDecoderModel
import torch


processor = TrOCRProcessor.from_pretrained("microsoft/trocr-base-handwritten")
model = VisionEncoderDecoderModel.from_pretrained("microsoft/trocr-base-handwritten")

pixel_values = processor(images=image, return_tensors="pt").pixel_values
generated_ids = model.generate(pixel_values, max_new_tokens=512)
generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]


print("ðŸ§¾ Extracted Handwritten Text:")
print("----------------------------------")
print(generated_text)



# ðŸ§° Step 1: Install Required Libraries
!pip install transformers
!pip install torch torchvision torchaudio
!pip install sentencepiece
!pip install Pillow